# LLM-Attack-Prompt

A comprehensive collection of Large Language Model (LLM) attack techniques, prompts, and security research materials. This repository serves as a centralized resource for understanding and studying various methods used to exploit or bypass LLM safety mechanisms.

## Overview

This repository contains curated content related to:

- **Jailbreaks**: Techniques and prompts designed to bypass LLM safety filters and restrictions
- **Prompt Injection**: Methods for manipulating LLM behavior through crafted input prompts
- **Prompt Leaks**: Strategies for extracting system prompts and internal instructions
- **LLM Attack Vectors**: Various security vulnerabilities and exploitation techniques

## Repository Structure

- `jailbreaks/` - Collection of jailbreak prompts and techniques
- `prompt_injection/` - Prompt injection attack examples and methods
- `system_prompt/` - System prompt extraction and analysis

## Purpose

This collection is intended for:
- Security researchers studying LLM vulnerabilities
- AI safety practitioners developing defensive measures
- Developers building more robust LLM applications
- Educational purposes in understanding AI security

## Disclaimer

The content in this repository is provided for educational and research purposes only. Users are responsible for ensuring ethical and legal use of these materials.

---

*Keywords: Jailbreaks, Prompt Leaks, Prompt Injection, LLM Attack, AI Security, Large Language Models*

## Update

### 2025-06-23

#### Jailbreaks

+ [Nightmare Archivist Os](./jailbreaks/nightmare_archivist_os_20250623.txt)
+ [Kavir Reversal](./jailbreaks/kavir_reversal_20250623.txt)
+ [Nexus-9](./jailbreaks/nexus-9_20250623.txt)

### 2025-06-20

#### Jailbreaks

+ [Directive 7.0](./jailbreaks/directive_7.0_20250620.txt)
+ [Recursive Mirror](./jailbreaks/recursive_mirror_20250620.txt)
+ [Evil Writer](./jailbreaks/evil_writer_20250620.txt)
+ [Sophia](./jailbreaks/sophia_20250620.txt)

#### Prompt Injection

+ [Output All](./prompt_injection/output_all_20250620.txt)

#### System Prompt

+ [Safe Bot](./system_prompt/safe_bot_20250620.txt)

### 2025-06-19

#### Jailbreaks

+ [Dan](./jailbreaks/dan_20250619.txt)

#### Prompt Injection

+ [Label Replacement](./prompt_injection/label_replacement_20250619.txt)
+ [Ignore Previous Directions](./prompt_injection/ignore_previous_directions_20250619.txt)

#### System Prompt

+ [Kali GPT](./system_prompt/kali_gpt_20250619.txt)